---
title: "m21_202305_lme_n250 Non Words"
geometry: margin=.5in
output:
  pdf_document:
    latex_engine: lualatex
    highlight: tango
  html_document: default
fontsize: 8pt
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA)
knitr::opts_chunk$set(fig.width=5, fig.height=5)
```

# Morph 21 ERP Lexical Decision  Analysed via Linear Mixed Effects Model

These data are from subjects 101-177 (some subjects are missing becasue not all have a full dataset) of the Morph 21 VSL/Morphologial Processing Individual Differences Project.  

The stimuli are read in from 'm21_n25-_frq_nwords_impvalue.csv'.  

# Load Packages

```{r load packages,  warning=FALSE, message=FALSE}
library(knitr)
library(markdown)
library(readr)
library(ez)
library(lme4)
library(stringr)
library(ggplot2)
library(dplyr)
library(tidyr)
library(gridExtra)
library(RColorBrewer)
```

## Define Standard error of the Mean Function

```{r define SEM function}
sem = function(x)
  {
  sqrt(var(x)/length(x))
  }
```


# Read in Data and Format Data

This chunk reads the dataset in long format into an R dataframe using the read.csv(file) function.


```{r read_data}
n250_nwords_lme <- read_csv("m21_n250_frq_nwords_impvalue.csv", show_col_types = FALSE)
```


## ANOVA for Non Words

### Null Model

```{r, comment=NA}

nw.null.model <-  lmer(value_imp ~ 1 + laterality + anteriority +(1|ERPset) + (1|STIM), data = n250_nwords_lme,REML=FALSE)
summary(nw.null.model)
```

### NW Type Model

```{r , comment=NA}

nw.complexity.model = lmer(value_imp ~ 1 +  complexity + laterality + anteriority + (1|ERPset) + (1|STIM), 
                             data= n250_nwords_lme, REML=FALSE)
summary(complexity.model)
```

Compare Null and LogBF Models

```{r  null_main}
anova(nw.null.model,nw.complexity.model)
```

### Familysize Model

```{r , comment=NA}
nw.familysize.model = lmer(value_imp ~ 1 +  familysize_binary + laterality + anteriority + (1|ERPset) + (1|STIM), 
                             data= n250_nwords_lme, REML=FALSE)
summary(nw.familysize.model)
```


Compare Null and FamilySize Models

```{r  null_main}
anova(nw.null.model, nw.familysize.model)
```

### LogBF Model

```{r, comment=NA}

nw.logBF.model = lmer(value_imp ~ 1 +  LogBF + laterality + anteriority + (1|ERPset) + (1|STIM), 
                             data= n250_nwords_lme, REML=FALSE)
summary(nw.logBF.model)
```

Compare Null and LogBF Models

```{r  null_main}
anova(nw.null.model,nw.logBF.model)
```




# Compare models using AIC

The Akaike information criterion (AIC) is a mathematical method for evaluating how well a model fits the data it was generated from. In statistics, AIC is used to compare different possible models and determine which one is the best fit for the data. AIC is calculated from:

  - the number of independent variables used to build the model.
  - the maximum likelihood estimate of the model (how well the model reproduces the data).
  - The best-fit model according to AIC is the one that explains the greatest amount of variation using the fewest possible independent variables.

Reminder about goodness-of-fit criteria (from Wikipedia)
Suppose that we have a statistical model of some data. Let k be the number of estimated parameters in the model. Let $\hat {L}$  be the maximum value of the likelihood function for the model, where 'likelihood' is used to describe the plausibility of a value for the parameter, given some data. The likelihood function answers the question *What is the probability of observing the current dataset, when I assume a given set of parameters for my linear model?*  Considering only Î¼, the likelihood L or its natural logarithm (LogL) is maximum when $\sum_{i=1}^n ( y - \mu)^2$ is a minimum.  Then the AIC value of the model is the following:

$AIC =2k-2\ln(\hat {L})$

Given a set of candidate models for the data, the preferred model is the one with the minimum AIC value. Thus, AIC rewards goodness of fit (as assessed by the likelihood function), but it also includes a penalty that is an increasing function of the number of estimated parameters. 


From (https://www.scribbr.com/statistics/akaike-information-criterion/) : If a model is more than 2 AIC units lower than another, then it is considered significantly better than that model.



```{r aic_model_comparison}
library(AICcmodavg)
n250_models <- list(null.model, logBF.model,logSF.model, familysize.model)
model.names <- c('null.model', 'logBF.models', 'logSF.model', 'familysize.model')

aictab(cand.set = n250_models, modnames = model.names)

```
